{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3500ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import os\n",
    "from mido.midifiles.meta import KeySignatureError\n",
    "from mido import MidiFile\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "from base import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "719d0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaMessage('time_signature', numerator=8, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=8, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=8, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=6, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=6, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=5, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=9, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=5, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=9, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=3, denominator=2, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=3, denominator=2, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=3, denominator=2, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=6, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=2, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=8, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=1, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=6, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=5, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=3, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=5, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=1, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=6, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=1)\n",
      "MetaMessage('time_signature', numerator=1, denominator=8, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=7, denominator=16, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0)\n",
      "MetaMessage('time_signature', numerator=7, denominator=16, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=121)\n"
     ]
    }
   ],
   "source": [
    "test_path = 'samples/music/flute/'\n",
    "\n",
    "files = os.listdir(test_path)\n",
    "mpb = []\n",
    "tpb = []\n",
    "f_files = []\n",
    "rolls = []\n",
    "for f in sorted(files)[:100]:\n",
    "    try:\n",
    "        t = 0\n",
    "        note_found = False\n",
    "        discard = False\n",
    "        mpb_i = None\n",
    "        mid_temp = MidiFile(os.path.join(test_path, f), clip=True)\n",
    "        notes = {\n",
    "            n: {'start': [], 'end': [], 'velocity': []}\n",
    "            for n in range(128)\n",
    "        }\n",
    "        for track in mid_temp.tracks:\n",
    "            for msg in track:\n",
    "                if not msg.is_meta:\n",
    "                    if msg.type == 'note_on':\n",
    "                        if note_found:\n",
    "                            t += msg.time\n",
    "                        else:\n",
    "                            t = 0\n",
    "                            note_found = True\n",
    "                        if msg.velocity > 0:\n",
    "                            notes[msg.note]['start'].append(t // mid_temp.ticks_per_beat)\n",
    "                            notes[msg.note]['velocity'].append(msg.velocity)\n",
    "                        else:\n",
    "                            notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                    if msg.type == 'note_off':\n",
    "                        t += msg.time\n",
    "                        notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                else:\n",
    "                    if msg.type == 'set_tempo':\n",
    "                        if mpb_i is None:\n",
    "                            mpb_i = msg.tempo\n",
    "                        else:\n",
    "                            discard = True\n",
    "                    elif msg.type == 'time_signature':\n",
    "                        if msg.numerator != 4 and  msg.denominator != 4:\n",
    "                            print(msg)\n",
    "\n",
    "        if not discard:\n",
    "            f_files.append(f) \n",
    "            tpb.append(mid_temp.ticks_per_beat)\n",
    "            mpb.append(mpb_i)\n",
    "            piano_roll = np.zeros((128, t // mid_temp.ticks_per_beat))\n",
    "            for n, events in notes.items():\n",
    "                if len(events['start']) > 0:\n",
    "                    for n_ini, n_end, v in zip(events['start'], events['end'], events['velocity']):\n",
    "                        piano_roll[n, n_ini:n_end] = v / 127\n",
    "            rolls.append(piano_roll)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ff4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logits(logits, target):\n",
    "    prediction = torch.max(logits, dim=1)[1]\n",
    "    return 1 - (prediction == target).float().mean()\n",
    "    \n",
    "    \n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, mlp_dim, heads):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim, heads, batch_first=True\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.mlp = nn.Linear(embed_dim, mlp_dim)\n",
    "\n",
    "    def forward(self, x_in, mask=None):\n",
    "        x = self.ln1(x_in)\n",
    "        x, _ = self.attention(\n",
    "            query=x, key=x, value=x, attn_mask=mask,\n",
    "            need_weights=False,\n",
    "        )\n",
    "        x = x + x_in\n",
    "\n",
    "        y = self.ln2(x)\n",
    "        y = self.mlp(y)\n",
    "\n",
    "        return x + y\n",
    "    \n",
    "\n",
    "class MusicTransformer(BaseModel):\n",
    "    \"\"\"\n",
    "        Transformer architecture for motifs inspired by\n",
    "        C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer,\n",
    "        I. Simon, C. Hawthorne, A. M. Dai, M. D. Hoffman,\n",
    "        M. Dinculescu and D. Eck\n",
    "        \"Music Transformer\"\n",
    "        https://arxiv.org/abs/1809.04281\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_depth=16,\n",
    "        decoder_depth=16,\n",
    "        device=torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        ),\n",
    "        notes=128,\n",
    "        bits=8,\n",
    "        multitokens=True,\n",
    "        heads=32,\n",
    "        lr=1e-3,\n",
    "        verbose=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Init values\n",
    "        self.epoch = None\n",
    "        self.t_train = 0\n",
    "        self.t_val = 0\n",
    "        self.heads = heads\n",
    "        self.device = device\n",
    "        self.multitokens = multitokens\n",
    "        if self.multitokens:            \n",
    "            channels = notes\n",
    "        else:\n",
    "            channels = 2 * notes + bits\n",
    "\n",
    "        # <Parameter setup>\n",
    "        self.encoder = nn.ModuleList([\n",
    "            SelfAttentionBlock(channels, channels, heads)\n",
    "            for _ in range(encoder_depth)\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            SelfAttentionBlock(channels, channels, heads)\n",
    "            for _ in range(decoder_depth)\n",
    "        ])\n",
    "\n",
    "        # <Loss function setup>\n",
    "        if self.multitokens:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "                {\n",
    "                    'name': 'mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': 'l1',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.l1_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '0mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.zeros_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '1mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.ones_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        else:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 0,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "                {\n",
    "                    'name': 'acc',\n",
    "                    'weight': 1,\n",
    "                    'f': accuracy_logits\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        # <Optimizer setup>\n",
    "        # We do this last step after all parameters are defined\n",
    "        model_params = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        # self.optimizer_alg = torch.optim.Adam(model_params, lr=lr)\n",
    "        self.optimizer_alg = torch.optim.SGD(model_params, lr=lr)\n",
    "        self.schedulers = [\n",
    "#             torch.optim.lr_scheduler.ExponentialLR(\n",
    "#                 self.optimizer_alg, gamma=0.9\n",
    "#             ),\n",
    "#             torch.optim.lr_scheduler.MultiStepLR(\n",
    "#                 self.optimizer_alg, milestones=[10, 30, 50, 80, 100, 150], gamma=0.1\n",
    "#             ),\n",
    "            torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer_alg, 'min'\n",
    "            )\n",
    "        ]\n",
    "        if verbose > 1:\n",
    "            print(\n",
    "                'Network created on device {:} with training losses '\n",
    "                '[{:}] and validation losses [{:}]'.format(\n",
    "                    self.device,\n",
    "                    ', '.join([tf['name'] for tf in self.train_functions]),\n",
    "                    ', '.join([vf['name'] for vf in self.val_functions])\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, data):\n",
    "        N, F, L = data.shape\n",
    "        mask = torch.ones((L, L), dtype=bool)\n",
    "        mask = torch.logical_not(torch.triu(mask)).to(self.device)\n",
    "        seq_range = torch.arange(0, data.shape[-1])\n",
    "        x_cord, y_cord = torch.meshgrid(seq_range, seq_range)\n",
    "        s_rel = 1 - torch.abs(x_cord - y_cord).type_as(data).to(data.device)\n",
    "        snorm_rel = s_rel / L\n",
    "        data = data.transpose(-1, -2)\n",
    "        for i, e_tf in enumerate(self.encoder):\n",
    "            e_tf.to(self.device)\n",
    "            data = e_tf(data, snorm_rel)\n",
    "        for i, d_tf in enumerate(self.decoder):\n",
    "            d_tf.to(self.device)\n",
    "            data = d_tf(data, mask)\n",
    "        return data.transpose(-1, -2)\n",
    "\n",
    "    def next_beat(self, motif):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            tensor_motif = torch.from_numpy(\n",
    "                np.expand_dims(motif, axis=0)\n",
    "            ).to(self.device)\n",
    "            if self.multitokens:\n",
    "                next_beat = torch.sigmoid(self(tensor_motif))\n",
    "            else:\n",
    "                next_beat = torch.softmax(self(tensor_motif), dim=1)\n",
    "\n",
    "        return next_beat.detach().cpu().numpy()[0, ...]\n",
    "\n",
    "    def song(self, motif, n_beats):\n",
    "        song_list = [motif]\n",
    "        song = [motif]\n",
    "        for _ in range(n_beats):\n",
    "            beat = self.next_beat(motif)\n",
    "            new_notes = deepcopy(beat)\n",
    "            if self.multitokens:\n",
    "                motif = (new_notes > 0.5).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_notes > 0.5\n",
    "                )\n",
    "            else:\n",
    "                new_tokens = deepcopy(beat)\n",
    "                max_val = np.max(new_tokens, axis=0, keepdims=True)\n",
    "                motif = (new_tokens == max_val).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_tokens == max_val\n",
    "                )\n",
    "\n",
    "        return np.concatenate(song_list, axis=1), np.concatenate(song, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f31c2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotifDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, paths=None, motif_size=64, notespbeat=12,\n",
    "            bits=8, multitokens=True\n",
    "    ):\n",
    "        # Init\n",
    "        if paths is None:\n",
    "            paths = ['samples/music/jazz/', 'samples/music/classical/']\n",
    "        self.multitokens = multitokens\n",
    "        self.motif_size = motif_size\n",
    "        self.rolls = []\n",
    "        self.states = []\n",
    "        self.bits = bits\n",
    "        min_len = 2 * self.motif_size + 1\n",
    "        beat = 0\n",
    "        for path in paths:\n",
    "            files = sorted(os.listdir(path))\n",
    "            for f in files:\n",
    "                t = 0\n",
    "                discard = False\n",
    "                mpb_i = None\n",
    "                note_found = False\n",
    "                try:\n",
    "                    mid_temp = MidiFile(os.path.join(path, f), clip=True)\n",
    "                    notes = {\n",
    "                        n: {'start': [], 'end': [], 'velocity': []}\n",
    "                        for n in range(128)\n",
    "                    }\n",
    "                    tpb = mid_temp.ticks_per_beat\n",
    "                    for track in mid_temp.tracks:\n",
    "                        for msg in track:\n",
    "                            if not msg.is_meta:\n",
    "                                if note_found:\n",
    "                                    t += msg.time\n",
    "                                if msg.type == 'note_on':\n",
    "                                    if not note_found:\n",
    "                                        t = 0\n",
    "                                        note_found = True\n",
    "                                    beat = t // tpb\n",
    "                                    if msg.velocity > 0:\n",
    "                                        notes[msg.note]['start'].append(beat)\n",
    "                                        notes[msg.note]['velocity'].append(\n",
    "                                            msg.velocity\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        notes[msg.note]['end'].append(beat)\n",
    "                                elif msg.type == 'note_off':\n",
    "                                    beat = t // tpb\n",
    "                                    notes[msg.note]['end'].append(beat)\n",
    "                            else:\n",
    "                                if msg.type == 'set_tempo':\n",
    "                                    if mpb_i is None:\n",
    "                                        mpb_i = msg.tempo\n",
    "                                    else:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "                                elif msg.type == 'time_signature':\n",
    "                                    num = msg.numerator\n",
    "                                    den = msg.denominator\n",
    "                                    if num != 4 and den != 4:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "\n",
    "                    if not discard:\n",
    "                        piano_roll = np.zeros((128, beat))\n",
    "                        for n, events in notes.items():\n",
    "                            if len(events['start']) > 0:\n",
    "                                for n_ini, n_end, v in zip(\n",
    "                                        events['start'], events['end'],\n",
    "                                        events['velocity']\n",
    "                                ):\n",
    "                                    # piano_roll[n, n_ini:n_end] = v / 127\n",
    "                                    piano_roll[n, n_ini:n_end] = 1\n",
    "                        max_notes = np.max(\n",
    "                            np.sum(piano_roll, axis=0)\n",
    "                        ).astype(int)\n",
    "                        piano_state = roll_to_state(\n",
    "                            piano_roll, bits=self.bits\n",
    "                        )\n",
    "                        roll_len = piano_roll.shape[1]\n",
    "                        if roll_len > min_len and max_notes < notespbeat:\n",
    "                            self.rolls.append(piano_roll)\n",
    "                        state_len = piano_state.shape[1]\n",
    "                        if state_len > min_len and max_notes < notespbeat:\n",
    "                            self.states.append(piano_state)\n",
    "                except (EOFError, OSError, KeySignatureError):\n",
    "                    print('Unreadable', f, path)\n",
    "\n",
    "        max_notes = [\n",
    "            np.max(np.sum(roll, axis=0)).astype(int)\n",
    "            for roll in self.rolls\n",
    "        ]\n",
    "        print(\n",
    "            '{:d} piano rolls loaded with '\n",
    "            '[{:02d}, {:02d}] - {:5.3f} ± {:5.3f} '\n",
    "            'maximum consecutive notes'.format(\n",
    "                len(self.rolls), np.min(max_notes), np.max(max_notes),\n",
    "                np.mean(max_notes), np.std(max_notes)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.multitokens:\n",
    "            song = self.rolls[index]\n",
    "        else:\n",
    "            song = self.states[index]\n",
    "        max_ini = song.shape[1] - (2 * self.motif_size)\n",
    "        data_ini = np.random.randint(0, max_ini)\n",
    "        target_ini = data_ini + self.motif_size\n",
    "        data = song[:, data_ini:target_ini].astype(np.float32)\n",
    "        target = song[:, target_ini:(target_ini + self.motif_size)].astype(np.float32)\n",
    "        if not self.multitokens:\n",
    "            target = np.argmax(target, axis=0)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.multitokens:\n",
    "            n_samples = len(self.rolls)\n",
    "        else:\n",
    "            n_samples = len(self.states)\n",
    "        return n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42ea036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens(shift, bits=4, notes=128):\n",
    "    remainder = shift\n",
    "    tokens = []\n",
    "    for shift_bit in range(bits - 1, -1, -1):\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[2 * notes + shift_bit] = 1\n",
    "        n_tokens = remainder // 2 ** shift_bit\n",
    "        remainder = remainder - n_tokens * 2 ** shift_bit\n",
    "        tokens += n_tokens * [token]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def on_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def off_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[notes + note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def roll_to_state(roll, bits=8, notes=128):\n",
    "    shift = 0\n",
    "    notes_active = np.array([])\n",
    "    token_list = []\n",
    "    for beat in roll.transpose():\n",
    "        if np.sum(beat) > 0:\n",
    "            played_notes = np.where(beat > 0)[0]\n",
    "            new_replayed = np.isin(played_notes, notes_active)\n",
    "            old_replayed = np.isin(notes_active, played_notes)\n",
    "            if new_replayed.all() and old_replayed.all():\n",
    "                # We are repeating everything\n",
    "                # print('Repeat', notes_active, played_notes, shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Changes\n",
    "                on = played_notes[np.logical_not(new_replayed)]\n",
    "                off = notes_active[np.logical_not(old_replayed)]\n",
    "                # print(\n",
    "                #     'OFF', off, 'ON', on, 'Data', notes_active, old_replayed,\n",
    "                #     played_notes, new_replayed, shift\n",
    "                # )\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(off, bits, notes)\n",
    "                token_list += on_tokens(on, bits, notes)\n",
    "                shift = 0\n",
    "            notes_active = played_notes\n",
    "        else:\n",
    "            if len(notes_active) == 0:\n",
    "                # Silence\n",
    "                # print('Silence', shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Notes go off\n",
    "                # print('OFF', notes_active, shift)\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(notes_active, bits, notes)\n",
    "                notes_active = np.array([])\n",
    "                shift = 0\n",
    "\n",
    "        shift += 1\n",
    "        \n",
    "    token_list += shift_tokens(shift, bits, notes)\n",
    "    \n",
    "    return np.stack(token_list, axis=1)\n",
    "\n",
    "\n",
    "def state_to_roll(states, bits=8, notes=128):\n",
    "    roll = []\n",
    "    active_notes = []\n",
    "    for state in states.transpose():\n",
    "        state_code = np.where(state)[0][0]\n",
    "        if state_code < notes:\n",
    "            # print('ON', state_code)\n",
    "            active_notes.append(state_code)\n",
    "        elif state_code < (2 * notes):\n",
    "            # print('OFF', state_code - notes)\n",
    "            try:\n",
    "                active_notes.remove(state_code - notes)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        else:\n",
    "            # print('Shift', 2 ** (state_code - 2 * notes))\n",
    "            shift = 2 ** (state_code - 2 * notes)\n",
    "            beat = np.zeros(notes)\n",
    "            for note in active_notes:\n",
    "                beat[note] = 1\n",
    "            roll += shift * [beat]\n",
    "    \n",
    "    return np.stack(roll, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "793c9254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 piano rolls loaded with [00, 01] - 0.973 ± 0.161 maximum consecutive notes\n"
     ]
    }
   ],
   "source": [
    "motif_size = 32\n",
    "bits = 16\n",
    "paths = [\n",
    "    # 'samples/music/giantpiano/',\n",
    "    'samples/music/flute/',\n",
    "    # 'samples/music/jazz/',\n",
    "#     'samples/music/maestro/',\n",
    "    # 'samples/music/mfiles/',\n",
    "    # 'samples/music/midiworld/',\n",
    "]\n",
    "dataset = MotifDataset(paths, motif_size=motif_size, bits=bits, notespbeat=20, multitokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a62b3bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise the low-dim structure of the train data\n",
    "t = dataset[0][0]\n",
    "sn.heatmap(t, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e6072c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ready 21266432 parameters\n",
      "Epoch num |  train  |   val   |   xent   |   mse    |    l1    |   0mse   |   1mse   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "----------|---------|---------|----------|----------|----------|----------|----------|\n",
      "\u001b[32mInit     \u001b[0m | \u001b[32m 4.5377\u001b[0m | \u001b[32m 4.5665\u001b[0m | \u001b[36m  4.5665\u001b[0m | \u001b[36m  0.4737\u001b[0m | \u001b[36m  0.5083\u001b[0m | \u001b[36m  0.0039\u001b[0m | \u001b[36m  0.9961\u001b[0m | 15s\n",
      "\u001b[32mEpoch 000\u001b[0m | \u001b[32m 1.9779\u001b[0m | \u001b[32m 0.9185\u001b[0m | \u001b[36m  0.9185\u001b[0m | \u001b[36m  0.1552\u001b[0m | \u001b[36m  0.1884\u001b[0m | \u001b[36m  0.0038\u001b[0m |   0.9962 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "\u001b[32mEpoch 001\u001b[0m | \u001b[32m 0.6152\u001b[0m | \u001b[32m 0.4061\u001b[0m | \u001b[36m  0.4061\u001b[0m | \u001b[36m  0.0817\u001b[0m | \u001b[36m  0.1103\u001b[0m |   0.0039 |   0.9961 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 002\u001b[0m | \u001b[32m 0.3196\u001b[0m | \u001b[32m 0.2326\u001b[0m | \u001b[36m  0.2326\u001b[0m | \u001b[36m  0.0473\u001b[0m | \u001b[36m  0.0689\u001b[0m |   0.0038 |   0.9962 | 49s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 003\u001b[0m | \u001b[32m 0.1994\u001b[0m | \u001b[32m 0.1702\u001b[0m | \u001b[36m  0.1702\u001b[0m | \u001b[36m  0.0331\u001b[0m | \u001b[36m  0.0501\u001b[0m |   0.0039 | \u001b[36m  0.9961\u001b[0m | 49s                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "\u001b[32mEpoch 004\u001b[0m | \u001b[32m 0.1460\u001b[0m | \u001b[32m 0.1322\u001b[0m | \u001b[36m  0.1322\u001b[0m | \u001b[36m  0.0245\u001b[0m | \u001b[36m  0.0387\u001b[0m |   0.0038 |   0.9962 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 005\u001b[0m | \u001b[32m 0.1248\u001b[0m | \u001b[32m 0.1047\u001b[0m | \u001b[36m  0.1047\u001b[0m | \u001b[36m  0.0184\u001b[0m | \u001b[36m  0.0301\u001b[0m |   0.0039 |   0.9961 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 006\u001b[0m | \u001b[32m 0.1014\u001b[0m | \u001b[32m 0.0906\u001b[0m | \u001b[36m  0.0906\u001b[0m | \u001b[36m  0.0155\u001b[0m | \u001b[36m  0.0256\u001b[0m |   0.0039 |   0.9961 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 007\u001b[0m |  0.1076 | \u001b[32m 0.0794\u001b[0m | \u001b[36m  0.0794\u001b[0m | \u001b[36m  0.0128\u001b[0m | \u001b[36m  0.0215\u001b[0m |   0.0038 |   0.9962 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\u001b[32mEpoch 008\u001b[0m | \u001b[32m 0.0820\u001b[0m | \u001b[32m 0.0736\u001b[0m | \u001b[36m  0.0736\u001b[0m | \u001b[36m  0.0115\u001b[0m | \u001b[36m  0.0197\u001b[0m |   0.0038 |   0.9962 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "\u001b[32mEpoch 009\u001b[0m | \u001b[32m 0.0801\u001b[0m | \u001b[32m 0.0664\u001b[0m | \u001b[36m  0.0664\u001b[0m | \u001b[36m  0.0099\u001b[0m | \u001b[36m  0.0174\u001b[0m |   0.0039 |   0.9961 | 48s                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "Training finished in 10 epochs (8m 20s) with minimum loss = 0.066447 (epoch 9)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights/all_multi.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     dataset, batch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m net_multi\u001b[39m.\u001b[39mfit(train_loader, val_loader, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m net_multi\u001b[39m.\u001b[39;49msave_model(\u001b[39m'\u001b[39;49m\u001b[39mweights/all_multi.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/OneDrive/Masters/BrainHack2022/brainharmonic/base.py:396\u001b[0m, in \u001b[0;36mBaseModel.save_model\u001b[0;34m(self, net_name)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_model\u001b[39m(\u001b[39mself\u001b[39m, net_name):\n\u001b[0;32m--> 396\u001b[0m     torch\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_dict(), net_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 377\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    378\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    379\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    232\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/all_multi.pt'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "net_multi = MusicTransformer(encoder_depth=128, decoder_depth=128, multitokens=True, heads=16)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_multi.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = True\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_multi.fit(train_loader, val_loader, epochs=10, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30a368e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_multi.save_model('weights/all_multi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c77c67d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ready 95326208 parameters\n",
      "Epoch num |  train  |   val   |   xent   |   acc    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "----------|---------|---------|----------|----------|\n",
      "\u001b[32mInit     \u001b[0m | \u001b[32m32.5795\u001b[0m | \u001b[32m 0.9986\u001b[0m | \u001b[36m 32.5649\u001b[0m | \u001b[36m  0.9986\u001b[0m | 10s\n",
      "\u001b[KEpoch 000 (006/014 - 42.86%) [████████            ] train_loss 40.106 (40.581) 9s / ETA 13s\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     dataset, batch_size, \u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     dataset, batch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m net_state\u001b[39m.\u001b[39;49mfit(train_loader, val_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m net_state\u001b[39m.\u001b[39msave_model(\u001b[39m'\u001b[39m\u001b[39mweights/all_state.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/OneDrive/Masters/BrainHack2022/brainharmonic/base.py:237\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, train_loader, val_loader, epochs, patience, verbose)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    236\u001b[0m \u001b[39m# First we train and check if there has been an improvement.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m loss_tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmini_batch_loop(train_loader)\n\u001b[1;32m    238\u001b[0m improvement_tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_loss_tr \u001b[39m>\u001b[39m loss_tr\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m improvement_tr:\n",
      "File \u001b[0;32m~/OneDrive/Masters/BrainHack2022/brainharmonic/base.py:108\u001b[0m, in \u001b[0;36mBaseModel.mini_batch_loop\u001b[0;34m(self, data, train)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    107\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m         batch_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    109\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_alg\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    110\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_update(\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "net_state = MusicTransformer(bits=bits, encoder_depth=128, decoder_depth=128, multitokens=False, heads=16)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_state.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = False\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_state.fit(train_loader, val_loader, epochs=10, patience=10)\n",
    "net_state.save_model('weights/all_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(rolls))\n",
    "random_roll = rolls[rand_idx]\n",
    "random_tpb = tpb[rand_idx]\n",
    "random_motif = random_roll[:, :motif_size].astype(np.float32)\n",
    "random_vel = np.mean(random_motif[random_motif > 0])\n",
    "song = random_roll[:, :motif_size + motif_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299141f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_multi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m p_song, pred_song \u001b[39m=\u001b[39m net_multi\u001b[39m.\u001b[39msong((random_motif \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), \u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m18\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_multi' is not defined"
     ]
    }
   ],
   "source": [
    "p_song, pred_song = net_multi.song((random_motif > 0).astype(np.float32), 1)\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sn.heatmap(p_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 2)\n",
    "sn.heatmap(pred_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 3)\n",
    "sn.heatmap(song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98522647",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m random_states \u001b[39m=\u001b[39m roll_to_state(random_motif \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, bits, \u001b[39m128\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m song_states \u001b[39m=\u001b[39m roll_to_state(random_roll \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, bits, \u001b[39m128\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m p_song, pred_song \u001b[39m=\u001b[39m net_state\u001b[39m.\u001b[39msong(random_states[:, :motif_size]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), \u001b[39m10\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_state' is not defined"
     ]
    }
   ],
   "source": [
    "random_states = roll_to_state(random_motif > 0, bits, 128)\n",
    "song_states = roll_to_state(random_roll > 0, bits, 128)\n",
    "p_song, pred_song = net_state.song(random_states[:, :motif_size].astype(np.float32), 10)\n",
    "plt.figure(figsize=(30, 40))\n",
    "plt.subplot(4, 1, 1)\n",
    "new_motifs = state_to_roll(pred_song, bits=bits, notes=128)\n",
    "final_song = np.concatenate([\n",
    "    random_motif,\n",
    "    new_motifs\n",
    "], axis=1)\n",
    "# sn.heatmap(final_song, cbar=False)\n",
    "min_size = min(song.shape[1], final_song.shape[1])\n",
    "sn.heatmap(p_song[:, :motif_size * 2], vmin=0, vmax=1, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 3)\n",
    "sn.heatmap(final_song[:, :min_size], cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 2)\n",
    "sn.heatmap(song_states[:, :motif_size * 2], cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 4)\n",
    "sn.heatmap(song[:, :min_size], cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fba9ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sn\u001b[39m.\u001b[39mheatmap(rolls[\u001b[39m6\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rolls[\u001b[39m0\u001b[39m][:, \u001b[39m63\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brendan/OneDrive/Masters/BrainHack2022/brainharmonic/transformer.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mlen\u001b[39m(dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(rolls[6])\n",
    "rolls[0][:, 63]\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0619a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(dataset[6])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
