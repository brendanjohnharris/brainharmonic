{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3500ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import os\n",
    "from mido import MidiFile\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "from base import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'samples/music/classical/'\n",
    "\n",
    "files = os.listdir(test_path)\n",
    "mpb = []\n",
    "tpb = []\n",
    "f_files = []\n",
    "rolls = []\n",
    "for f in sorted(files)[:100]:\n",
    "    try:\n",
    "        t = 0\n",
    "        note_found = False\n",
    "        discard = False\n",
    "        mpb_i = None\n",
    "        mid_temp = MidiFile(os.path.join(test_path, f), clip=True)\n",
    "        notes = {\n",
    "            n: {'start': [], 'end': [], 'velocity': []}\n",
    "            for n in range(128)\n",
    "        }\n",
    "        for track in mid_temp.tracks:\n",
    "            for msg in track:\n",
    "                if not msg.is_meta:\n",
    "                    if msg.type == 'note_on':\n",
    "                        if note_found:\n",
    "                            t += msg.time\n",
    "                        else:\n",
    "                            t = 0\n",
    "                            note_found = True\n",
    "                        if msg.velocity > 0:\n",
    "                            notes[msg.note]['start'].append(t // mid_temp.ticks_per_beat)\n",
    "                            notes[msg.note]['velocity'].append(msg.velocity)\n",
    "                        else:\n",
    "                            notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                    if msg.type == 'note_off':\n",
    "                        t += msg.time\n",
    "                        notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                else:\n",
    "                    if msg.type == 'set_tempo':\n",
    "                        if mpb_i is None:\n",
    "                            mpb_i = msg.tempo\n",
    "                        else:\n",
    "                            discard = True\n",
    "                    elif msg.type == 'time_signature':\n",
    "                        if msg.numerator != 4 and  msg.denominator != 4:\n",
    "                            print(msg)\n",
    "\n",
    "        if not discard:\n",
    "            f_files.append(f) \n",
    "            tpb.append(mid_temp.ticks_per_beat)\n",
    "            mpb.append(mpb_i)\n",
    "            piano_roll = np.zeros((128, t // mid_temp.ticks_per_beat))\n",
    "            for n, events in notes.items():\n",
    "                if len(events['start']) > 0:\n",
    "                    for n_ini, n_end, v in zip(events['start'], events['end'], events['velocity']):\n",
    "                        piano_roll[n, n_ini:n_end] = v / 127\n",
    "            rolls.append(piano_roll)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ff4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logits(logits, target):\n",
    "    prediction = torch.max(logits, dim=1)[1]\n",
    "    return 1 - (prediction == target).float().mean()\n",
    "    \n",
    "    \n",
    "class MultiheadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "        Mmulti-headed attention based on\n",
    "        A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, Ll. Jones, A.N. Gomez,\n",
    "        L. Kaiser, I. Polosukhin\n",
    "        \"Attention Is All You Need\"\n",
    "        https://arxiv.org/abs/1706.03762\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, in_features, att_features, heads=32,\n",
    "            masked=False, norm=partial(torch.softmax, dim=1),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.blocks = heads\n",
    "        self.init_norm = nn.InstanceNorm1d(in_features)\n",
    "        # self.init_norm = nn.GroupNorm(1, in_features)\n",
    "        # self.init_norm = nn.BatchNorm1d(in_features)\n",
    "        self.sa_blocks = nn.ModuleList([\n",
    "            SelfAttention(\n",
    "                in_features, att_features, masked, norm\n",
    "            )\n",
    "            for _ in range(self.blocks)\n",
    "        ])\n",
    "        self.final_block = nn.Sequential(\n",
    "            # nn.GroupNorm(heads, in_features * heads),\n",
    "            # nn.BatchNorm1d(in_features * heads),\n",
    "            nn.InstanceNorm1d(in_features * heads),\n",
    "            # nn.GroupNorm(1, in_features * heads),\n",
    "            nn.Conv1d(in_features * heads, in_features * heads, 1),\n",
    "            nn.ReLU(),\n",
    "            # nn.GroupNorm(heads, in_features * heads),\n",
    "            # nn.BatchNorm1d(in_features * heads),\n",
    "            nn.InstanceNorm1d(in_features * heads),\n",
    "            # nn.GroupNorm(1, in_features * heads),\n",
    "            nn.Conv1d(in_features * heads, in_features, 1)            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm_x = self.init_norm(x)\n",
    "        sa = torch.cat([sa_i(norm_x) for sa_i in self.sa_blocks], dim=1)\n",
    "        z = self.final_block(sa) + x\n",
    "        return z\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "        Non-local self-attention block based on\n",
    "        X. Wang, R. Girshick, A.Gupta, K. He\n",
    "        \"Non-local Neural Networks\"\n",
    "        https://arxiv.org/abs/1711.07971\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, in_features, att_features, masked=False,\n",
    "            norm=partial(torch.softmax, dim=1)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.features = att_features\n",
    "        self.map_key = nn.Conv1d(in_features, att_features, 1)\n",
    "        self.map_query = nn.Conv1d(in_features, att_features, 1)\n",
    "        self.map_value = nn.Conv1d(in_features, in_features, 1)\n",
    "        self.masked = masked\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        # key = F.layer_norm(self.map_key(x))\n",
    "        key = self.map_key(x)\n",
    "        # query = F.layer_norm(self.map_query(x))\n",
    "        query = self.map_query(x)\n",
    "        # value = F.layer_norm(self.map_value(x))\n",
    "        value = self.map_value(x)\n",
    "\n",
    "        seq_range = torch.arange(0, x.shape[-1])\n",
    "        att = torch.bmm(key.transpose(1, 2), query)\n",
    "        x_cord, y_cord = torch.meshgrid(seq_range, seq_range)\n",
    "        s_rel = 1 - torch.abs(x_cord - y_cord).type_as(x).to(x.device)\n",
    "        snorm_rel = s_rel / x.shape[-1]\n",
    "        # att_map = self.norm((att + snorm_rel) / np.sqrt(self.features))\n",
    "        if self.masked:\n",
    "            # masked_att = torch.triu(att)\n",
    "            masked_att = torch.triu(att + snorm_rel)\n",
    "            att_map = self.norm(masked_att / np.sqrt(self.features))\n",
    "        else:\n",
    "            # att_map = self.norm(att / np.sqrt(self.features))\n",
    "            att_map = self.norm((att + snorm_rel) / np.sqrt(self.features))\n",
    "\n",
    "        self_att = torch.bmm(value, att_map)\n",
    "\n",
    "        return torch.bmm(value, att_map) + x\n",
    "    \n",
    "\n",
    "class MusicTransformer(BaseModel):\n",
    "    \"\"\"\n",
    "        Transformer architecture for motifs inspired by\n",
    "        C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer,\n",
    "        I. Simon, C. Hawthorne, A. M. Dai, M. D. Hoffman,\n",
    "        M. Dinculescu and D. Eck\n",
    "        \"Music Transformer\"\n",
    "        https://arxiv.org/abs/1809.04281\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        att_filters=None,\n",
    "        device=torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        ),\n",
    "        notes=128,\n",
    "        bits=8,\n",
    "        multitokens=True,\n",
    "        heads=128,\n",
    "        verbose=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Init values\n",
    "        self.epoch = None\n",
    "        self.t_train = 0\n",
    "        self.t_val = 0\n",
    "        self.device = device\n",
    "        self.multitokens = multitokens\n",
    "        if self.multitokens:            \n",
    "            channels = notes\n",
    "        else:\n",
    "            channels = 2 * notes + bits\n",
    "            \n",
    "        if att_filters is None:\n",
    "            self.att_filters = [channels // 2, channels // 4, channels // 8]\n",
    "        else:\n",
    "            self.att_filters = att_filters\n",
    "\n",
    "        # <Parameter setup>\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                MultiheadedAttention(channels, f_att, heads, masked=False),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for f_att in att_filters\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                MultiheadedAttention(channels, f_att, heads, masked=True),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for f_att in att_filters[:0:-1]\n",
    "        ])\n",
    "        self.final = MultiheadedAttention(\n",
    "            channels, self.att_filters[0], heads, masked=True\n",
    "        )\n",
    "\n",
    "        # <Loss function setup>\n",
    "        if self.multitokens:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "                {\n",
    "                    'name': 'mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': 'l1',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.l1_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '0mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.zeros_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '1mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.ones_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        else:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "                {\n",
    "                    'name': 'acc',\n",
    "                    'weight': 0,\n",
    "                    'f': accuracy_logits\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        # <Optimizer setup>\n",
    "        # We do this last step after all parameters are defined\n",
    "        model_params = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        self.optimizer_alg = torch.optim.Adam(model_params, lr=1e-3)\n",
    "        if verbose > 1:\n",
    "            print(\n",
    "                'Network created on device {:} with training losses '\n",
    "                '[{:}] and validation losses [{:}]'.format(\n",
    "                    self.device,\n",
    "                    ', '.join([tf['name'] for tf in self.train_functions]),\n",
    "                    ', '.join([vf['name'] for vf in self.val_functions])\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, data):\n",
    "        for i, e_tf in enumerate(self.encoder):\n",
    "            e_tf.to(self.device)\n",
    "            data = e_tf(data)\n",
    "        for i, d_tf in enumerate(self.decoder):\n",
    "            d_tf.to(self.device)\n",
    "            data = d_tf(data)\n",
    "        self.final.to(self.device)\n",
    "        return self.final(data)\n",
    "\n",
    "    def next_beat(self, motif):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            tensor_motif = torch.from_numpy(\n",
    "                np.expand_dims(motif, axis=0)\n",
    "            ).to(self.device)\n",
    "            if self.multitokens:\n",
    "                next_beat = torch.sigmoid(self(tensor_motif))\n",
    "            else:\n",
    "                next_beat = torch.softmax(self(tensor_motif), dim=1)\n",
    "\n",
    "        return next_beat.detach().cpu().numpy()[0, ...]\n",
    "\n",
    "    def song(self, motif, n_beats):\n",
    "        song_list = [motif]\n",
    "        song = [motif]\n",
    "        for _ in range(n_beats):\n",
    "            beat = self.next_beat(motif)\n",
    "            new_notes = deepcopy(beat)\n",
    "            if self.multitokens:\n",
    "                motif = (new_notes > 0.5).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_notes > 0.5\n",
    "                )\n",
    "            else:\n",
    "                new_tokens = deepcopy(beat)\n",
    "                max_val = np.max(new_tokens, axis=0, keepdims=True)\n",
    "                motif = (new_tokens == max_val).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_tokens == max_val\n",
    "                )\n",
    "\n",
    "        return np.concatenate(song_list, axis=1), np.concatenate(song, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31c2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotifDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, paths=None, motif_size=64, notespbeat=12,\n",
    "            bits=8, multitokens=True\n",
    "    ):\n",
    "        # Init\n",
    "        if paths is None:\n",
    "            paths = ['samples/music/jazz/', 'samples/music/classical/']\n",
    "        self.multitokens = multitokens\n",
    "        self.motif_size = motif_size\n",
    "        self.rolls = []\n",
    "        self.states = []\n",
    "        self.bits = bits\n",
    "        min_len = 2 * self.motif_size + 1\n",
    "        beat = 0\n",
    "        for path in paths:\n",
    "            files = sorted(os.listdir(path))\n",
    "            for f in files:\n",
    "                t = 0\n",
    "                discard = False\n",
    "                mpb_i = None\n",
    "                note_found = False\n",
    "                try:\n",
    "                    mid_temp = MidiFile(os.path.join(path, f), clip=True)\n",
    "                    notes = {\n",
    "                        n: {'start': [], 'end': [], 'velocity': []}\n",
    "                        for n in range(128)\n",
    "                    }\n",
    "                    tpb = mid_temp.ticks_per_beat\n",
    "                    for track in mid_temp.tracks:\n",
    "                        for msg in track:\n",
    "                            if not msg.is_meta:\n",
    "                                if note_found:\n",
    "                                    t += msg.time\n",
    "                                if msg.type == 'note_on':\n",
    "                                    if not note_found:\n",
    "                                        t = 0\n",
    "                                        note_found = True\n",
    "                                    beat = t // tpb\n",
    "                                    if msg.velocity > 0:\n",
    "                                        notes[msg.note]['start'].append(beat)\n",
    "                                        notes[msg.note]['velocity'].append(\n",
    "                                            msg.velocity\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        notes[msg.note]['end'].append(beat)\n",
    "                                elif msg.type == 'note_off':\n",
    "                                    beat = t // tpb\n",
    "                                    notes[msg.note]['end'].append(beat)\n",
    "                            else:\n",
    "                                if msg.type == 'set_tempo':\n",
    "                                    if mpb_i is None:\n",
    "                                        mpb_i = msg.tempo\n",
    "                                    else:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "                                elif msg.type == 'time_signature':\n",
    "                                    num = msg.numerator\n",
    "                                    den = msg.denominator\n",
    "                                    if num != 4 and den != 4:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "\n",
    "                    if not discard:\n",
    "                        piano_roll = np.zeros((128, beat))\n",
    "                        for n, events in notes.items():\n",
    "                            if len(events['start']) > 0:\n",
    "                                for n_ini, n_end, v in zip(\n",
    "                                        events['start'], events['end'],\n",
    "                                        events['velocity']\n",
    "                                ):\n",
    "                                    # piano_roll[n, n_ini:n_end] = v / 127\n",
    "                                    piano_roll[n, n_ini:n_end] = 1\n",
    "                        max_notes = np.max(\n",
    "                            np.sum(piano_roll, axis=0)\n",
    "                        ).astype(int)\n",
    "                        piano_state = roll_to_state(\n",
    "                            piano_roll, bits=self.bits\n",
    "                        )\n",
    "                        roll_len = piano_roll.shape[1]\n",
    "                        if roll_len > min_len and max_notes < notespbeat:\n",
    "                            self.rolls.append(piano_roll)\n",
    "                        state_len = piano_state.shape[1]\n",
    "                        if state_len > min_len and max_notes < notespbeat:\n",
    "                            self.states.append(piano_state)\n",
    "                except EOFError:\n",
    "                    print('Unreadable', f)\n",
    "\n",
    "        max_notes = [\n",
    "            np.max(np.sum(roll, axis=0)).astype(int)\n",
    "            for roll in self.rolls\n",
    "        ]\n",
    "        print(\n",
    "            '{:d} piano rolls loaded with '\n",
    "            '[{:02d}, {:02d}] - {:5.3f} ± {:5.3f}'.format(\n",
    "                len(self.rolls), np.min(max_notes), np.max(max_notes),\n",
    "                np.mean(max_notes), np.std(max_notes)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.multitokens:\n",
    "            song = self.rolls[index]\n",
    "        else:\n",
    "            song = self.states[index]\n",
    "        max_ini = song.shape[1] - (2 * self.motif_size)\n",
    "        data_ini = np.random.randint(0, max_ini)\n",
    "        target_ini = data_ini + self.motif_size\n",
    "        data = song[:, data_ini:target_ini].astype(np.float32)\n",
    "        target = song[:, target_ini:(target_ini + self.motif_size)].astype(np.float32)\n",
    "        if not self.multitokens:\n",
    "            target = np.argmax(target, axis=0)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.multitokens:\n",
    "            n_samples = len(self.rolls)\n",
    "        else:\n",
    "            n_samples = len(self.states)\n",
    "        return n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ea036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens(shift, bits=4, notes=128):\n",
    "    remainder = shift\n",
    "    tokens = []\n",
    "    for shift_bit in range(bits - 1, -1, -1):\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[2 * notes + shift_bit] = 1\n",
    "        n_tokens = remainder // 2 ** shift_bit\n",
    "        remainder = remainder - n_tokens * 2 ** shift_bit\n",
    "        tokens += n_tokens * [token]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def on_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def off_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[notes + note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def roll_to_state(roll, bits=8, notes=128):\n",
    "    shift = 0\n",
    "    notes_active = np.array([])\n",
    "    token_list = []\n",
    "    for beat in roll.transpose():\n",
    "        if np.sum(beat) > 0:\n",
    "            played_notes = np.where(beat > 0)[0]\n",
    "            new_replayed = np.isin(played_notes, notes_active)\n",
    "            old_replayed = np.isin(notes_active, played_notes)\n",
    "            if new_replayed.all() and old_replayed.all():\n",
    "                # We are repeating everything\n",
    "                # print('Repeat', notes_active, played_notes, shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Changes\n",
    "                on = played_notes[np.logical_not(new_replayed)]\n",
    "                off = notes_active[np.logical_not(old_replayed)]\n",
    "                # print(\n",
    "                #     'OFF', off, 'ON', on, 'Data', notes_active, old_replayed,\n",
    "                #     played_notes, new_replayed, shift\n",
    "                # )\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(off, bits, notes)\n",
    "                token_list += on_tokens(on, bits, notes)\n",
    "                shift = 0\n",
    "            notes_active = played_notes\n",
    "        else:\n",
    "            if len(notes_active) == 0:\n",
    "                # Silence\n",
    "                # print('Silence', shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Notes go off\n",
    "                # print('OFF', notes_active, shift)\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(notes_active, bits, notes)\n",
    "                notes_active = np.array([])\n",
    "                shift = 0\n",
    "\n",
    "        shift += 1\n",
    "        \n",
    "    token_list += shift_tokens(shift, bits, notes)\n",
    "    \n",
    "    return np.stack(token_list, axis=1)\n",
    "\n",
    "\n",
    "def state_to_roll(states, bits=8, notes=128):\n",
    "    roll = []\n",
    "    active_notes = []\n",
    "    for state in states.transpose():\n",
    "        state_code = np.where(state)[0][0]\n",
    "        if state_code < notes:\n",
    "            # print('ON', state_code)\n",
    "            active_notes.append(state_code)\n",
    "        elif state_code < (2 * notes):\n",
    "            # print('OFF', state_code - notes)\n",
    "            active_notes.remove(state_code - notes)\n",
    "        else:\n",
    "            # print('Shift', 2 ** (state_code - 2 * notes))\n",
    "            shift = 2 ** (state_code - 2 * notes)\n",
    "            beat = np.zeros(notes)\n",
    "            for note in active_notes:\n",
    "                beat[note] = 1\n",
    "            roll += shift * [beat]\n",
    "    \n",
    "    return np.stack(roll, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c61d348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "motif_size = 64\n",
    "rand_idx = np.random.randint(0, len(rolls))\n",
    "random_roll = rolls[rand_idx]\n",
    "song = random_roll[:, :2 * motif_size] \n",
    "bin_song = song > 0\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(4, 1, 1)\n",
    "sn.heatmap(song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 2)\n",
    "sn.heatmap(song > 0, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])  \n",
    "plt.subplot(4, 1, 3)\n",
    "states = roll_to_state(song > 0)\n",
    "sn.heatmap(states, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 4)\n",
    "roll = state_to_roll(states)\n",
    "sn.heatmap(roll, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c9254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreadable Leifs, Jón, 4 Piano Pieces, Op.2, qgJ2dV6L3Ac.mid\n",
      "Unreadable Liszt, Franz, Concerto pathétique, S.258, VkZPzfwL0xw.mid\n"
     ]
    }
   ],
   "source": [
    "motif_size = 32\n",
    "paths = [\n",
    "    'samples/music/giantpiano/',\n",
    "    'samples/music/classical/',\n",
    "    'samples/music/maestro/',\n",
    "]\n",
    "dataset = MotifDataset(paths, motif_size=motif_size, notespbeat=20, multitokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6072c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "net_multi = MusicTransformer([32] * 8, multitokens=True, heads=32)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_multi.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = True\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_multi.fit(train_loader, val_loader, epochs=10, patience=10)\n",
    "net_multi.save_model('weights/all_multi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "net_state = MusicTransformer([32] * 8, multitokens=False, heads=32)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_state.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = False\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_state.fit(train_loader, val_loader, epochs=10, patience=10)\n",
    "net_state.save_model('weights/all_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(rolls))\n",
    "random_roll = rolls[rand_idx]\n",
    "random_tpb = tpb[rand_idx]\n",
    "random_motif = random_roll[:, :motif_size].astype(np.float32)\n",
    "random_vel = np.mean(random_motif[random_motif > 0])\n",
    "song = random_roll[:, :motif_size + motif_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_song, pred_song = net_multi.song((random_motif > 0).astype(np.float32), 1)\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sn.heatmap(p_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 2)\n",
    "sn.heatmap(pred_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 3)\n",
    "sn.heatmap(song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98522647",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = roll_to_state(random_motif > 0, 8, 128)\n",
    "p_song, pred_song = net_state.song(random_states.astype(np.float32), 1)\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "new_motif = state_to_roll(pred_song[:, random_states.shape[-1]:], bits=8, notes=128)\n",
    "final_song = np.concatenate([\n",
    "    random_motif,\n",
    "    new_motif[:, :motif_size]\n",
    "], axis=1)\n",
    "# sn.heatmap(final_song, cbar=False)\n",
    "sn.heatmap(p_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 2)\n",
    "sn.heatmap(final_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 3)\n",
    "sn.heatmap(song[:, :final_song.shape[1]], cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fba9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
